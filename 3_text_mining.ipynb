{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973df272",
   "metadata": {},
   "source": [
    "# Text Mining \n",
    "\n",
    "## 1. Pr√©processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"flickr_data_clustered.parquet\")\n",
    "print(f\"Donn√©es charg√©es : {len(df)} photos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71074a77",
   "metadata": {},
   "source": [
    "### D√©finition des stopwords\n",
    "\n",
    "On d√©finit une liste de stopwords fran√ßaise et anglaise minimale, en gardant uniquement les mots non-pertinents pour identifier les lieux touristiques de Lyon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21580870",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = {\n",
    "    \n",
    "}\n",
    "\n",
    "print(f\"Nombre total de stopwords : {len(stopwords)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da970c1",
   "metadata": {},
   "source": [
    "### Fonction de nettoyage du texte\n",
    "\n",
    "On cr√©e une fonction qui :\n",
    "1. Concat√®ne title et tags\n",
    "2. Met en minuscules\n",
    "3. Supprime les accents (√© ‚Üí e, √ß ‚Üí c)\n",
    "4. Supprime la ponctuation et caract√®res sp√©ciaux\n",
    "5. Filtre les stopwords et mots trop courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_text(title, tags):\n",
    "    \"\"\"\n",
    "    Nettoie et combine title et tags en une liste de mots pertinents.\n",
    "    \n",
    "    Args:\n",
    "        title: Titre de la photo (str ou NaN)\n",
    "        tags: Tags de la photo (str ou NaN)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de mots nettoy√©s\n",
    "    \"\"\"\n",
    "    # Combiner title et tags\n",
    "    text = \"\"\n",
    "    if isinstance(title, str):\n",
    "        text += title + \" \"\n",
    "    if isinstance(tags, str):\n",
    "        text += tags\n",
    "    \n",
    "    if not text.strip():\n",
    "        return []\n",
    "    \n",
    "    # 1. Minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Supprimer accents et caract√®res sp√©ciaux Unicode\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "    \n",
    "    # 3. Ne garder que lettres et espaces (supprime [, ], {, }, etc.)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # 4. Split et filtrer\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stopwords and len(w) > 2]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Test de la fonction\n",
    "test_title = \"[Lyon] Basilique de Fourvi√®re - √ât√© 2024\"\n",
    "test_tags = \"france, architecture, √©glise, photo\"\n",
    "print(\"Test de nettoyage :\")\n",
    "print(f\"Input : '{test_title}' + '{test_tags}'\")\n",
    "print(f\"Output : {clean_text(test_title, test_tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a7f3a",
   "metadata": {},
   "source": [
    "### Application du nettoyage\n",
    "\n",
    "On applique la fonction de nettoyage sur toutes les photos pour cr√©er une colonne unique `cleaned_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le nettoyage sur title + tags\n",
    "df['cleaned_text'] = df.apply(\n",
    "    lambda row: clean_text(row['title'], row['tags']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Statistiques sur le nettoyage\n",
    "total_photos = len(df)\n",
    "photos_avec_mots = (df['cleaned_text'].str.len() > 0).sum()\n",
    "photos_sans_mots = total_photos - photos_avec_mots\n",
    "\n",
    "print(f\"‚úì Nettoyage termin√©\")\n",
    "print(f\"  - Photos avec mots : {photos_avec_mots} ({photos_avec_mots/total_photos*100:.1f}%)\")\n",
    "print(f\"  - Photos sans mots : {photos_sans_mots} ({photos_sans_mots/total_photos*100:.1f}%)\")\n",
    "print(f\"  - Nombre moyen de mots/photo : {df['cleaned_text'].str.len().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d848f",
   "metadata": {},
   "source": [
    "### V√©rification du r√©sultat\n",
    "\n",
    "On affiche quelques exemples pour v√©rifier que le nettoyage fonctionne correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c706af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher quelques exemples\n",
    "sample = df[df['cleaned_text'].str.len() > 0].sample(n=10, random_state=42)\n",
    "\n",
    "print(\"Exemples de textes nettoy√©s :\\n\")\n",
    "for idx, row in sample.iterrows():\n",
    "    print(f\"Title original : {row['title'][:80]}...\")\n",
    "    print(f\"Tags originaux : {row['tags'][:80] if isinstance(row['tags'], str) else 'N/A'}...\")\n",
    "    print(f\"Mots nettoy√©s  : {row['cleaned_text'][:10]}\")  # 10 premiers mots\n",
    "    print(f\"Cluster        : {row['cluster_hdbscan']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8ca8e",
   "metadata": {},
   "source": [
    "## 2. M√©thode 1 : Mot le plus fr√©quent par cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021bbe3",
   "metadata": {},
   "source": [
    "Ensuite on on cherche le mot qui correspond √† chaque cluster\n",
    "df : le dataframe \n",
    "cluster_kmeans : le nom de la colonne qui contient le num de cluster auquel appartient la ligne\n",
    "texte_cols : les colonnes o√π y a les textes qu'on va utiliser pour identifier les mots les plus fr√©quent \n",
    "top_k : nb de mots √† garder = 1 puisque on cherche un seul mots par cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bdd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def cluster_titles(\n",
    "    df,\n",
    "    cluster_hdbscan=\"cluster_hdbscan\",\n",
    "    text_cols=(\"cleaned_title\", \"cleaned_tags\"),\n",
    "    top_k=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Retourne un titre (mot-cl√©) par cluster bas√© sur les mots les plus fr√©quents\n",
    "    \"\"\"\n",
    "    cluster_labels = {}\n",
    "\n",
    "    for cluster_id in sorted(df[cluster_hdbscan].unique()):\n",
    "        if cluster_id == -1:\n",
    "            continue  # on ignore le bruit\n",
    "\n",
    "        # sous-dataframe du cluster (seulement les ligne de ce cluster)\n",
    "        dff = df[df[cluster_hdbscan] == cluster_id]\n",
    "\n",
    "        # concat√©nation des textes de toutes les lignes\n",
    "        all_words = []\n",
    "        #on parcours les deux colonnes de texte\n",
    "        for col in text_cols:\n",
    "            texts = dff[col].dropna()\n",
    "            for t in texts:\n",
    "                all_words.extend(t)\n",
    "        # si la liste est vide donc pas de mots\n",
    "        if not all_words:\n",
    "            cluster_labels[cluster_id] = \"unknown\"\n",
    "            continue\n",
    "\n",
    "        # comptage des mots\n",
    "        counts = Counter(all_words)\n",
    "\n",
    "        # mots les plus fr√©quents\n",
    "        top_words = [w for w, _ in counts.most_common(top_k)]\n",
    "\n",
    "        # Retourner le premier mot (string) au lieu d'une liste\n",
    "        cluster_labels[cluster_id] = top_words[0] if top_words else \"unknown\"\n",
    "\n",
    "    return cluster_labels\n",
    "\n",
    "df['cluster_name'] = df['cluster_hdbscan'].map(\n",
    "    cluster_titles(df, top_k=1)\n",
    ").fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier ce que retourne la fonction\n",
    "print(\"Premiers cluster_name:\")\n",
    "print(df[['cluster_hdbscan', 'cluster_name']].head(20))\n",
    "print(\"\\nTypes:\")\n",
    "print(df['cluster_name'].dtype)\n",
    "print(\"\\nValeurs uniques (10 premi√®res):\")\n",
    "print(df['cluster_name'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher TOUS les clusters avec leurs titres\n",
    "cluster_summary = df[df['cluster_hdbscan'] != -1].groupby('cluster_hdbscan').agg({\n",
    "    'cluster_name': 'first',\n",
    "    'id': 'count'\n",
    "}).rename(columns={'id': 'nb_photos'}).sort_values('nb_photos', ascending=False)\n",
    "\n",
    "print(f\"Liste compl√®te des {len(cluster_summary)} clusters avec leurs titres:\\n\")\n",
    "print(cluster_summary.to_string())\n",
    "\n",
    "# Ou en DataFrame pour mieux voir\n",
    "cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36955775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de clusters HDBSCAN\n",
    "n_clusters = len(df[df['cluster_hdbscan'] != -1]['cluster_hdbscan'].unique())\n",
    "n_bruit = len(df[df['cluster_hdbscan'] == -1])\n",
    "n_total = len(df)\n",
    "\n",
    "print(f\"üìä Statistiques HDBSCAN:\")\n",
    "print(f\"  ‚Ä¢ Nombre de clusters: {n_clusters}\")\n",
    "print(f\"  ‚Ä¢ Points de bruit (-1): {n_bruit} ({n_bruit/n_total*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Points dans des clusters: {n_total - n_bruit} ({(n_total-n_bruit)/n_total*100:.1f}%)\")\n",
    "print(f\"\\nTaille des 10 plus gros clusters:\")\n",
    "print(df[df['cluster_hdbscan'] != -1]['cluster_hdbscan'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce955f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "sample = df.sample(n=min(30000, len(df)), random_state=0)\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[df[\"lat\"].median(), df[\"long\"].median()],\n",
    "    zoom_start=12,\n",
    "    tiles=\"CartoDB positron\"\n",
    ")\n",
    "\n",
    "palette = [\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"darkred\", \"lightred\", \n",
    "           \"beige\", \"darkblue\", \"darkgreen\", \"cadetblue\", \"darkpurple\", \n",
    "           \"pink\", \"lightblue\", \"lightgreen\", \"gray\", \"black\", \"lightgray\"]\n",
    "\n",
    "for _, r in sample.iterrows():\n",
    "    cluster = r[\"cluster_hdbscan\"]\n",
    "    if cluster == -1:\n",
    "        color = \"lightgray\"\n",
    "    else:\n",
    "        color = palette[cluster % len(palette)]\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[r[\"lat\"], r[\"long\"]],\n",
    "        radius=2,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.6,\n",
    "        popup=folium.Popup(\n",
    "            f\"\"\"<b>Keyword:</b> {r[\"cluster_name\"]}<br/>\n",
    "               <a href=\"{r[\"url\"]}\" target=\"_blank\">Open Flickr</a>\"\"\",\n",
    "            max_width=250\n",
    "        )\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5a2f8",
   "metadata": {},
   "source": [
    "## 3. M√©thode 2 : TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914ba61",
   "metadata": {},
   "source": [
    "On tente une autre approche pour d√©crire chaque cluster : le TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34645b6b",
   "metadata": {},
   "source": [
    "On commence par combiner les listes de mots pour chaque photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a876c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les listes de mots nettoy√©s en un seul texte par photo\n",
    "df['combined_text'] = df.apply(\n",
    "    lambda row: ' '.join(row['cleaned_title_stopwords'] + row['cleaned_tags_stopwords']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# V√©rifier le r√©sultat\n",
    "df[['cleaned_title_stopwords', 'cleaned_tags_stopwords', 'combined_text', 'cluster_hdbscan']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d1dcf",
   "metadata": {},
   "source": [
    "Pour chaque cluster, on combine les textes de toutes les photos appartenant √† ce cluster en un seul document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7523d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_documents = df.groupby('cluster_hdbscan')['combined_text'].apply(\n",
    "    lambda texts: ' '.join(texts)\n",
    ").reset_index()\n",
    "\n",
    "cluster_documents.columns = ['cluster', 'document']\n",
    "\n",
    "# Afficher les premiers clusters avec leur taille de texte\n",
    "cluster_documents['text_length'] = cluster_documents['document'].str.len()\n",
    "cluster_documents[['cluster', 'text_length']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b7a6a",
   "metadata": {},
   "source": [
    "On calcule ensuite le TF-IDF pour chaque mot dans chaque document de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Cr√©er le vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Garder les 5000 mots les plus importants\n",
    "    min_df=2,           # Le mot doit appara√Ætre dans au moins 2 clusters\n",
    "    max_df=0.8          # Le mot ne doit pas √™tre dans plus de 80% des clusters\n",
    ")\n",
    "\n",
    "# Calculer la matrice TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(cluster_documents['document'])\n",
    "\n",
    "# Voir la forme de la matrice\n",
    "print(f\"Matrice TF-IDF : {tfidf_matrix.shape}\")\n",
    "print(f\"(nombre_clusters √ó nombre_termes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcaabf",
   "metadata": {},
   "source": [
    "On extrait ensuite le top k mots avec les scores TF-IDF les plus √©lev√©s pour chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# R√©cup√©rer les noms des termes\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Fonction pour extraire les top N termes d'un cluster\n",
    "def get_top_terms(cluster_idx, n=10):\n",
    "    # R√©cup√©rer les scores TF-IDF pour ce cluster\n",
    "    scores = tfidf_matrix[cluster_idx].toarray().flatten()\n",
    "    \n",
    "    # Obtenir les indices des top termes\n",
    "    top_indices = scores.argsort()[-n:][::-1]\n",
    "    \n",
    "    # Cr√©er un dataframe\n",
    "    top_terms = pd.DataFrame({\n",
    "        'term': feature_names[top_indices],\n",
    "        'tfidf_score': scores[top_indices]\n",
    "    })\n",
    "    \n",
    "    return top_terms\n",
    "\n",
    "# Afficher les top termes du cluster 0\n",
    "print(\"Top 10 termes du cluster 0 :\")\n",
    "get_top_terms(0, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab86105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les top 10 termes des 5 premiers clusters\n",
    "for i in range(min(5, len(cluster_documents))):\n",
    "    cluster_id = cluster_documents.iloc[i]['cluster']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CLUSTER {cluster_id} - Top 10 termes :\")\n",
    "    print(f\"{'='*60}\")\n",
    "    display(get_top_terms(i, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder avec la colonne cluster_name\n",
    "df.to_parquet(\"flickr_data_clusters_mined.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
